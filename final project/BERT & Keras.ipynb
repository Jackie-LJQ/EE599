{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mybert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr-oVzwCepJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
<<<<<<< HEAD
        "outputId": "30f938d0-68f2-4a20-d647-97be84dd0b5d"
=======
        "outputId": "248502cd-a045-4459-849e-9c86faa1963b"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzG1sx3PjWsJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
<<<<<<< HEAD
        "outputId": "82dbd821-64f8-41ed-9022-ea8e6a85744c"
=======
        "outputId": "f0fb02f6-8ad4-4f92-b217-a18341ecda9b"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, GRU, Dense, Dropout\n",
        "!git clone https://github.com/google-research/bert.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'bert' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1gpp7wj5qIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "from bert import tokenization\n",
        "from bert import modeling\n",
        "# from bert import extract_features\n",
        "# from bert import run_classifier"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtDHFN3vjv09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
<<<<<<< HEAD
        "outputId": "5497be75-3f89-401b-e7c2-eca81b6b9d65"
=======
        "outputId": "13f3659a-71cb-4500-a2ae-98d03301d85d"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "df_data = pd.read_csv('/content/drive/My Drive/data/ner_dataset.csv')\n",
        "print(df_data.head(10))\n",
        "df_data = df_data.iloc[:10000]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    Sentence #           Word  POS    Tag\n",
            "0  Sentence: 1      Thousands  NNS      O\n",
            "1  Sentence: 1             of   IN      O\n",
            "2  Sentence: 1  demonstrators  NNS      O\n",
            "3  Sentence: 1           have  VBP      O\n",
            "4  Sentence: 1        marched  VBN      O\n",
            "5  Sentence: 1        through   IN      O\n",
            "6  Sentence: 1         London  NNP  B-geo\n",
            "7  Sentence: 1             to   TO      O\n",
            "8  Sentence: 1        protest   VB      O\n",
            "9  Sentence: 1            the   DT      O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZE7MYo4hSVd",
        "colab_type": "text"
      },
      "source": [
        "Get the token of words form vocab, convert the token to number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmbA88BGa0S1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFCQgaqWX7c0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "getter = SentenceGetter(df_data)\n",
        "sentences = [[s[0] for s in sent] for sent in getter.sentences]\n",
        "labels = [[s[2] for s in sent] for sent in getter.sentences]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42sx2j2CYqh4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
<<<<<<< HEAD
        "outputId": "c50d9a93-76c3-4268-9469-77bf84dd84a0"
=======
        "outputId": "6a220581-625c-4dca-8926-802fb146de55"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "print(sentences[0])\n",
        "print(labels[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPVblq2KZbAk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
<<<<<<< HEAD
        "outputId": "f8c85be6-509f-499f-f11c-2536cacfa050"
=======
        "outputId": "8f7323bf-92df-42fa-fe55-efbbbfc57872"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "vocab='/content/drive/My Drive/data/cased_L-12_H-768_A-12/vocab.txt'\n",
        "tokenizer = tokenization.FullTokenizer(vocab,do_lower_case=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtZ_YAAbeEMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
<<<<<<< HEAD
        "outputId": "a0e946ab-26ef-46b4-b8e7-4163f52aefef"
=======
        "outputId": "272206d2-6ee7-4b28-bb9c-d1067debfeb5"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "tokenizer.tokenize('demonstrators') #'demonstrators'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['demons', '##tra', '##tors']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvbxBjz-ayQi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
<<<<<<< HEAD
        "outputId": "1811a677-b32e-4e49-d93d-6d246fcd5fc7"
=======
        "outputId": "7365bc9c-d146-4639-c80c-ba41f2ce547b"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "txt_token = []\n",
        "token_label = [] # sentences num * word in sentence\n",
        "for sentence, label1 in zip(sentences, labels):\n",
        "  word_list, label_list = ['[CLS]'], ['[CLS]']\n",
        "  for word, label in zip(sentence, label1):\n",
        "    token_list=tokenizer.tokenize(word)\n",
        "    for i, j in enumerate(token_list):\n",
        "      word_list.append(j)\n",
        "      if i == 0:\n",
        "        label_list.append(label)\n",
        "      else:\n",
        "        label_list.append('X') #explore\n",
        "  word_list.append('[SEP]')\n",
        "  label_list.append('[SEP]')\n",
        "  txt_token.append(word_list)\n",
        "  token_label.append(label_list)       \n",
        "\n",
        "print(txt_token[0])\n",
        "print(token_label[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Thousands', 'of', 'demons', '##tra', '##tors', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.', '[SEP]']\n",
            "['[CLS]', 'O', 'O', 'O', 'X', 'X', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSdGXwD7bbbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
<<<<<<< HEAD
        "outputId": "832807f8-fe93-4baf-834d-6eb8e57f7bcb"
=======
        "outputId": "7cb1a763-0e5a-4b1f-92fb-a6d33a1dc656"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "input_ids = []\n",
        "for i in txt_token:\n",
        "  temp = tokenizer.convert_tokens_to_ids(i)\n",
        "  input_ids.append(temp)\n",
        "print('input_id 0',input_ids[0])\n",
        "print(tokenizer.convert_tokens_to_ids(','))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_id 0 [101, 26159, 1104, 8568, 4487, 5067, 1138, 9639, 1194, 1498, 1106, 5641, 1103, 1594, 1107, 5008, 1105, 4555, 1103, 10602, 1104, 1418, 2830, 1121, 1115, 1583, 119, 102]\n",
            "[117]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AULzSJVgrb85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
<<<<<<< HEAD
        "outputId": "740a88e7-1d54-415e-cbf5-4a855c764ada"
=======
        "outputId": "1750ec47-a410-45ad-b90b-2d38873b691a"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "max_len = int(np.median([len(x) for x in input_ids])*1.5)\n",
        "print(max_len)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU4UzI7ymQ5C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
<<<<<<< HEAD
        "outputId": "97c90ed6-a984-46f9-d827-e7e4f135c580"
=======
        "outputId": "0f815c82-3641-43f8-d8be-e3cd86bc415a"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "input_ids = pad_sequences(input_ids, maxlen=max_len, dtype='int32' ,padding='post', truncating='post')\n",
        "print(input_ids[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101 26159  1104  8568  4487  5067  1138  9639  1194  1498  1106  5641\n",
            "  1103  1594  1107  5008  1105  4555  1103 10602  1104  1418  2830  1121\n",
            "  1115  1583   119   102     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fj9rjSPsZe2",
        "colab_type": "text"
      },
      "source": [
        "Convert the tag label to numeracal label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN4XxuDdrqat",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
<<<<<<< HEAD
        "outputId": "293fc8dd-4ba0-476b-de2f-e2dc2d3c6c7f"
=======
        "outputId": "380f8ab0-95a8-4698-e7f2-3870bb73c0a7"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "tag2id = {}\n",
        "j=0\n",
        "for i in df_data['Tag'].unique():\n",
        "  tag2id[i]=j\n",
        "  j+=1\n",
        "tag2id['X']=17\n",
        "tag2id['[CLS]']=18\n",
        "tag2id['[SEP]']=19\n",
        "tag2id"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-art': 8,\n",
              " 'B-eve': 14,\n",
              " 'B-geo': 1,\n",
              " 'B-gpe': 2,\n",
              " 'B-nat': 13,\n",
              " 'B-org': 5,\n",
              " 'B-per': 3,\n",
              " 'B-tim': 7,\n",
              " 'I-art': 9,\n",
              " 'I-eve': 15,\n",
              " 'I-geo': 4,\n",
              " 'I-gpe': 11,\n",
              " 'I-nat': 16,\n",
              " 'I-org': 6,\n",
              " 'I-per': 10,\n",
              " 'I-tim': 12,\n",
              " 'O': 0,\n",
              " 'X': 17,\n",
              " '[CLS]': 18,\n",
              " '[SEP]': 19}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXXAE-qWte5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
<<<<<<< HEAD
        "outputId": "c186dd3f-b49e-4fba-e575-ae9059e5ace4"
=======
        "outputId": "a7e23f03-0932-401d-b253-09023861296f"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "output_ids=[]\n",
        "for i in token_label:\n",
        "  temp=[]\n",
        "  for j in i:\n",
        "    temp.append(tag2id[j])\n",
        "  output_ids.append(temp)\n",
        "print(output_ids[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18, 0, 0, 0, 17, 17, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 19]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFdxNtcYvWHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
<<<<<<< HEAD
        "outputId": "b05bb100-30d9-4af5-a278-c412e726a7b2"
=======
        "outputId": "7d338b22-7df5-4bab-cf38-7c4baf39da1c"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "output_ids = pad_sequences(output_ids, maxlen=max_len,dtype='long',padding='post', truncating='post')\n",
        "print(output_ids[0])\n",
        "len(output_ids[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18  0  0  0 17 17  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  2  0  0\n",
            "  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZFHXWe3w-kL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split to train, val and test data\n",
        "tr_inputs, val_inputs, tr_ouputs, val_ouputs = train_test_split(input_ids, output_ids, test_size=0.4)\n",
        "val_inputs, test_inputs, val_ouputs, test_ouputs = train_test_split(val_inputs, val_ouputs, test_size=0.5)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1pDEiYVFG0L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
<<<<<<< HEAD
        "outputId": "a126c21e-38da-4553-b2d6-ad001bbc89b3"
=======
        "outputId": "85ca3fb2-a6e3-4c9a-a065-e02c89076066"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "# For test data, record how many real words in each sentence\n",
        "temp = np.sign(test_ouputs)\n",
        "print(temp.shape)\n",
        "print(test_ouputs.shape)\n",
        "print(temp[0])\n",
        "real_length = np.sum(temp,axis=1)\n",
        "print(real_length.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(92, 40)\n",
            "(92, 40)\n",
<<<<<<< HEAD
            "[1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
=======
            "[1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
            " 0 0 0]\n",
            "(92,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNx9vJIE2-kk",
        "colab_type": "text"
      },
      "source": [
        "Create the mask id and segment_id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCRhW8LE1P7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
<<<<<<< HEAD
        "outputId": "4d422bef-4214-4f43-bab8-7513a90e0ab4"
=======
        "outputId": "7dd39918-aac8-459d-d2d1-54e6039a023c"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "# The mask id is 1 for real input words, is 0 for padding words\n",
        "input_mask = [[0 if j==0 else 1 for j in i] for i in tr_inputs]\n",
        "print('inputmask 0',input_mask[0])\n",
        "print(len(input_mask))\n",
        "\n",
        "val_mask = [[0 if j==0 else 1 for j in i] for i in val_inputs]\n",
        "print('valinput mask', val_mask[0])\n",
        "\n",
        "test_mask = [[0 if j==0 else 1 for j in i] for i in test_inputs]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "inputmask 0 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "274\n",
            "valinput mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
=======
            "inputmask 0 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "274\n",
            "valinput mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_QivIRg4ujC",
        "colab_type": "text"
      },
      "source": [
        "Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPzAixqnEKrR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
<<<<<<< HEAD
        "outputId": "40e5acb9-5df9-49e1-e0fe-ac410d47fca2"
=======
        "outputId": "b994d92b-c442-4de3-9276-85f330ba20a8"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "temp = tokenization.load_vocab(vocab)\n",
        "vocab_size = len(temp)\n",
        "print(vocab_size)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ql67lgxGQLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_config = modeling.BertConfig.from_json_file('/content/drive/My Drive/data/cased_L-12_H-768_A-12/bert_config.json')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiJZ-zStEAf_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
<<<<<<< HEAD
        "outputId": "43066713-f773-48db-b355-b0f4bc93b7c8"
=======
        "outputId": "e7cd646c-7d57-467e-e2d8-b79c2316de08"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "#create bert model & get tr_input word embedding\n",
        "model = modeling.BertModel(\n",
        "    config=bert_config,\n",
        "    is_training=True,\n",
        "    input_ids = tf.convert_to_tensor(tr_inputs),\n",
        "    input_mask=tf.convert_to_tensor(input_mask),\n",
        ")\n",
        "embedding = model.get_sequence_output() #[batch_size, seq_length, hidden_size]\n",
        "print('input embedding:', embedding)\n",
        "seq_length = embedding.shape[1].value\n",
        "print('sequence length:',seq_length)\n",
        "num_seq = embedding.shape[0].value\n",
        "input_size = embedding.shape[2].value\n",
        "#check pool_output\n",
        "# model.get_pooled_output()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /content/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "input embedding: Tensor(\"bert/encoder/Reshape_13:0\", shape=(274, 40, 768), dtype=float32)\n",
            "sequence length: 40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zlDTgR2CSwN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
<<<<<<< HEAD
        "outputId": "637abed1-4e34-4c7a-f231-5d9ab19e67d0"
=======
        "outputId": "04e1c019-b15b-4f15-c28a-dc872e4005ee"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "# get val word embedding\n",
        "model = modeling.BertModel(\n",
        "    config=bert_config,\n",
        "    is_training=False,\n",
        "    input_ids = tf.convert_to_tensor(val_inputs),\n",
        "    input_mask=tf.convert_to_tensor(val_mask),\n",
        ")\n",
        "val_embedding = model.get_sequence_output() #[batch_size, seq_length, hidden_size]\n",
        "print('val_embedding', val_embedding)\n",
        "val_seq_num = val_embedding.shape[0].value"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "val_embedding Tensor(\"bert_1/encoder/Reshape_13:0\", shape=(91, 40, 768), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvk8uE9WetDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
<<<<<<< HEAD
        "outputId": "6594269e-bce7-4634-d817-1b4099668481"
=======
        "outputId": "69acdeb0-e1f4-468b-a3fe-6b3bdafed335"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "# get test word embedding\n",
        "model = modeling.BertModel(\n",
        "    config=bert_config,\n",
        "    is_training=False,\n",
        "    input_ids = tf.convert_to_tensor(test_inputs),\n",
        "    input_mask=tf.convert_to_tensor(test_mask),\n",
        ")\n",
        "test_embedding = model.get_sequence_output() #[batch_size, seq_length, hidden_size]\n",
        "print('test_embedding', test_embedding)\n",
        "test_seq_num = test_embedding.shape[0].value"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_embedding Tensor(\"bert_2/encoder/Reshape_13:0\", shape=(92, 40, 768), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7hiZKrNkDG3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
<<<<<<< HEAD
        "outputId": "c2650b8e-1143-4ff5-a55c-e2b3c1e80cb7"
=======
        "outputId": "0fe642b3-53eb-40da-d6e1-190750fe0a68"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "inputs = keras.Input(shape=(seq_length,input_size))\n",
        "training = GRU(10,return_sequences=True,stateful=False)(inputs)\n",
        "dense1 = layers.Dense(50, activation='relu')(training)\n",
        "# use mse loss\n",
        "# output = layers.Dense(1, activation='relu')(dense1) \n",
        "# use sparse loss\n",
        "output = layers.Dense(20, activation='softmax')(dense1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2CdOsL-qaBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras_model = keras.Model(inputs=inputs, outputs=output)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0R_p1ALqYdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
<<<<<<< HEAD
        "outputId": "32b01aae-b306-4de3-d166-5c15218dcb0b"
=======
        "outputId": "53328a3f-2a82-43c4-b23e-faee9dde2801"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "keras_model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 40, 768)]         0         \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 40, 10)            23370     \n",
            "_________________________________________________________________\n",
            "dense_111 (Dense)            (None, 40, 50)            550       \n",
            "_________________________________________________________________\n",
            "dense_112 (Dense)            (None, 40, 20)            1020      \n",
            "=================================================================\n",
            "Total params: 24,940\n",
            "Trainable params: 24,940\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jignhG4Lqui5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use mse loss\n",
        "# keras_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYCeVKQU6Ew-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use sparse and sgd\n",
        "sgd = tf.keras.optimizers.SGD(learning_rate=0.00001, momentum=0.0, nesterov=False, name='SGD')\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "keras_model.compile(loss=loss, optimizer=sgd, metrics=['categorical_accuracy'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lslPIZWrnu7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
<<<<<<< HEAD
        "outputId": "9d0ab488-b2d8-4b91-8afb-ffa66d10fa9b"
=======
        "outputId": "54c9d243-fdcd-4293-bc7b-2fba45018276"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "tr_ouputs = tf.reshape(tr_ouputs, [num_seq,seq_length,1]) #change tr_ouputs to 3 dimension to feed in model\n",
        "val_ouputs = tf.reshape(val_ouputs, [val_seq_num, seq_length,1])\n",
        "val_ouputs"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Reshape_1:0' shape=(91, 40, 1) dtype=int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTM7mytfpyFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "session = tf.InteractiveSession()\n",
        "session.run(tf.global_variables_initializer())"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBRWLM_Uq38h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
<<<<<<< HEAD
        "outputId": "10f20b05-7f24-494e-c856-58d931fac7f7"
=======
        "outputId": "78666404-3ca0-4d81-e9d4-970e5cee83bf"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "history = keras_model.fit(embedding/255, tr_ouputs/255,\n",
        "                    epochs=5,\n",
        "                    steps_per_epoch=50 , validation_data = (val_embedding/255, val_ouputs/255), validation_steps=50)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 50 samples, validate on 91 samples\n",
            "Epoch 1/5\n",
<<<<<<< HEAD
            "50/50 [==============================] - 93s 2s/step - loss: 2.9959 - categorical_accuracy: 8.3212e-04 - val_loss: 2.9970 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 93s 2s/step - loss: 2.9952 - categorical_accuracy: 0.0063 - val_loss: 2.9964 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 93s 2s/step - loss: 2.9945 - categorical_accuracy: 0.0371 - val_loss: 2.9959 - val_categorical_accuracy: 2.7473e-04\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 92s 2s/step - loss: 2.9939 - categorical_accuracy: 0.1468 - val_loss: 2.9953 - val_categorical_accuracy: 0.0014\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 93s 2s/step - loss: 2.9932 - categorical_accuracy: 0.3674 - val_loss: 2.9947 - val_categorical_accuracy: 0.0047\n"
=======
            "50/50 [==============================] - 93s 2s/step - loss: 2.9934 - categorical_accuracy: 0.3647 - val_loss: 2.9945 - val_categorical_accuracy: 0.1475\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 93s 2s/step - loss: 2.9926 - categorical_accuracy: 0.6109 - val_loss: 2.9938 - val_categorical_accuracy: 0.3643\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 93s 2s/step - loss: 2.9918 - categorical_accuracy: 0.8083 - val_loss: 2.9930 - val_categorical_accuracy: 0.6044\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 93s 2s/step - loss: 2.9910 - categorical_accuracy: 0.9223 - val_loss: 2.9923 - val_categorical_accuracy: 0.8214\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 93s 2s/step - loss: 2.9902 - categorical_accuracy: 0.9729 - val_loss: 2.9916 - val_categorical_accuracy: 0.9162\n"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0G_js3hvLPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "keras_model.save('/content/model.h5')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9vOQxh5ZIvz",
        "colab_type": "text"
      },
      "source": [
        "Make prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woT-NwSLdR-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
<<<<<<< HEAD
        "outputId": "e42d4890-525b-4b7a-98d8-d0a0185f438b"
=======
        "outputId": "38a1a6e0-dc81-4fba-c769-0c5c35050008"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "id2tag = {tag2id[key]:key for key in tag2id}\n",
        "id2tag"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'O',\n",
              " 1: 'B-geo',\n",
              " 2: 'B-gpe',\n",
              " 3: 'B-per',\n",
              " 4: 'I-geo',\n",
              " 5: 'B-org',\n",
              " 6: 'I-org',\n",
              " 7: 'B-tim',\n",
              " 8: 'B-art',\n",
              " 9: 'I-art',\n",
              " 10: 'I-per',\n",
              " 11: 'I-gpe',\n",
              " 12: 'I-tim',\n",
              " 13: 'B-nat',\n",
              " 14: 'B-eve',\n",
              " 15: 'I-eve',\n",
              " 16: 'I-nat',\n",
              " 17: 'X',\n",
              " 18: '[CLS]',\n",
              " 19: '[SEP]'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVkDRg8KO6Fo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
<<<<<<< HEAD
          "height": 67
        },
        "outputId": "7e5f81a9-3d08-43be-e63c-139806570bfb"
=======
          "height": 84
        },
        "outputId": "6c230349-4325-4da6-c2b2-0ae34649dfec"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "predict1 = keras_model.predict(test_embedding, steps=1)\n",
        "predict1 = np.array([[np.where(w==max(w)) for w in s] for s in predict1])\n",
        "predict1 = predict1.reshape((test_seq_num,seq_length))\n",
        "print('predict shape ',predict1.shape)\n",
        "# predict1 = np.rint(predict1)\n",
        "predict1[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict shape  (92, 40)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "array([5, 8, 5, 5, 5, 7, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 4, 5, 4, 5, 4,\n",
              "       5, 5, 5, 4, 4, 4, 5, 4, 4, 5, 4, 4, 4, 5, 4, 4, 4, 5])"
=======
              "array([11, 11, 11, 11, 11,  3,  9, 11,  6, 11, 11, 11, 11,  9, 11,  6, 11,\n",
              "       11, 11, 11,  6,  6, 11, 19, 11, 11,  3, 11, 11, 11, 11, 11, 11, 11,\n",
              "       11, 11,  3,  3,  8, 11])"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8FDdRbjjgAB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
<<<<<<< HEAD
        "outputId": "735f57b7-446d-4b4f-b321-101fa1fe837f"
=======
        "outputId": "fc995c5d-504e-4bae-b765-5a6d91cbe75b"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "predict2 = []\n",
        "for i in range(test_seq_num):\n",
        "  temp = real_length[i]\n",
        "  predict2.append(predict1[i][:temp])\n",
        "predict2[:3]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
<<<<<<< HEAD
              "[array([5, 8, 5]),\n",
              " array([5, 4, 8, 5, 5, 8, 5, 7, 5]),\n",
              " array([ 5,  5,  5,  5,  8, 13,  5,  5,  7,  5,  8,  8,  5,  5,  5,  5,  5,\n",
              "         5])]"
=======
              "[array([11, 11, 11, 11, 11,  3,  9, 11]),\n",
              " array([11, 11, 11, 11, 11,  6,  9, 11,  6]),\n",
              " array([11, 11, 11, 11, 11,  6,  9,  6,  6,  6, 11,  8, 11,  3,  6,  6, 11,\n",
              "        14,  9, 11])]"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlnrDEs9lgsq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
<<<<<<< HEAD
        "outputId": "e8533add-876c-425b-b98c-048db0c9bb60"
=======
        "outputId": "480633e7-e7ac-40a1-9a63-5b9048cd3171"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      },
      "source": [
        "predict = [[id2tag[i] for i in temp] for temp in predict2]\n",
        "print(predict[0])"
      ],
<<<<<<< HEAD
      "execution_count": 37,
=======
      "execution_count": 43,
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
      "outputs": [
        {
          "output_type": "stream",
          "text": [
<<<<<<< HEAD
            "['B-org', 'B-art', 'B-org']\n"
=======
            "['I-gpe', 'I-gpe', 'I-gpe', 'I-gpe', 'I-gpe', 'B-per', 'I-art', 'I-gpe']\n"
>>>>>>> f1b797716086f14177b65367284e2977cdec2806
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}