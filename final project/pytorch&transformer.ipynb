{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch&transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZpl7pgGp89W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6ZKl0RYqNSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V80AgRwqLuw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQpBg6wUqLGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5432f227-a3a9-4b58-9158-6b9c501fa26e"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm,trange\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertConfig, AutoModelWithLMHead\n",
        "from transformers import BertForTokenClassification, AdamW\n",
        "from seqeval.metrics import f1_score\n",
        "from seqeval.metrics import classification_report,accuracy_score,f1_score"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqhszCXtqwxy",
        "colab_type": "text"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4uePRs2qtaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data = pd.read_csv('/content/drive/My Drive/data/ner_dataset.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONSivsuJq-6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data.head(5)\n",
        "df_data = df_data[:10000]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U70Gb4rurjj_",
        "colab_type": "text"
      },
      "source": [
        "Combine words that in the same sentence *together*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVlpJlAnrefN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzSGoxXOs_ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "getter = SentenceGetter(df_data)\n",
        "sentences = [[s[0] for s in sent] for sent in getter.sentences]\n",
        "labels = [[s[2] for s in sent] for sent in getter.sentences]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3QgPc8AgPXE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "9eaec415-b0d2-4dab-a0d0-caf6e6161274"
      },
      "source": [
        "df_data.Tag.value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        8483\n",
              "B-gpe     303\n",
              "B-geo     244\n",
              "I-per     206\n",
              "B-org     176\n",
              "B-per     160\n",
              "B-tim     149\n",
              "I-org     140\n",
              "I-geo      31\n",
              "B-art      28\n",
              "I-gpe      20\n",
              "I-art      20\n",
              "I-tim      13\n",
              "B-eve      10\n",
              "I-eve      10\n",
              "B-nat       5\n",
              "I-nat       2\n",
              "Name: Tag, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5l_FxMitEox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3b87258c-31a9-4edc-8d75-5105b7244e97"
      },
      "source": [
        "print(sentences[0])\n",
        "print(labels[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzix_Fk9tjZ-",
        "colab_type": "text"
      },
      "source": [
        "Tokenize words, create mask id, segment id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr3kdhGmtWi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = '/content/drive/My Drive/data/cased_L-12_H-768_A-12/vocab.txt'\n",
        "tokenizer=BertTokenizer(vocab_file=vocab,do_lower_case=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcXT0rw0uqi0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "ecd6c138-1aa8-4761-dd92-18552ff88811"
      },
      "source": [
        "txt_token = []\n",
        "token_label = [] # sentences num * word in sentence\n",
        "for sentence, label1 in zip(sentences, labels):\n",
        "  word_list, label_list = ['[CLS]'], ['[CLS]']\n",
        "  for word, label in zip(sentence, label1):\n",
        "    token_list=tokenizer.tokenize(word)\n",
        "    for i, j in enumerate(token_list):\n",
        "      word_list.append(j)\n",
        "      if i == 0:\n",
        "        label_list.append(label)\n",
        "      else:\n",
        "        label_list.append('X') #explore\n",
        "  word_list.append('[SEP]')\n",
        "  label_list.append('[SEP]')\n",
        "  txt_token.append(word_list)\n",
        "  token_label.append(label_list)       \n",
        "\n",
        "print(txt_token[0])\n",
        "print(token_label[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Thousands', 'of', 'demons', '##tra', '##tors', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.', '[SEP]']\n",
            "['[CLS]', 'O', 'O', 'O', 'X', 'X', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUcBkPzAu4-4",
        "colab_type": "text"
      },
      "source": [
        "Set token embedding, pad or trim the sequence to the max length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY69zGrQvD9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb044fc2-2516-4972-c937-4175ee044845"
      },
      "source": [
        "max_len = np.median([len(x) for x in txt_token]) \n",
        "max_len= int(1.5*max_len)\n",
        "print(max_len)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckc2DxGAvneq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "85bc983b-3b6b-4fb8-eeb3-26ccc08da921"
      },
      "source": [
        "input_ids = []\n",
        "for i in txt_token:\n",
        "  temp = tokenizer.convert_tokens_to_ids(i)\n",
        "  #print(temp)\n",
        "  input_ids.append(temp)\n",
        "input_ids = pad_sequences(input_ids, maxlen=max_len,dtype='long',padding='post', truncating='post')\n",
        "print(input_ids[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101 26159  1104  8568  4487  5067  1138  9639  1194  1498  1106  5641\n",
            "  1103  1594  1107  5008  1105  4555  1103 10602  1104  1418  2830  1121\n",
            "  1115  1583   119   102     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIsFg_i2ycEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mask id\n",
        "mask = [[0 if j==0 else 1 for j in i] for i in input_ids]\n",
        "# create segment id\n",
        "segment_id = np.zeros(input_ids.shape)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0GKk0_2tR7F",
        "colab_type": "text"
      },
      "source": [
        "Convert tags to labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdVNMkU4tFSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make convert dictionary\n",
        "tag2id = {}\n",
        "j=1\n",
        "for i in df_data['Tag'].unique():\n",
        "  tag2id[i]=j\n",
        "  j+=1\n",
        "tag2id['X']=17\n",
        "tag2id['[CLS]']=18\n",
        "tag2id['[SEP]']=19\n",
        "# tag2id"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUOURGWxv8bd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "07d89b67-b533-4b24-8db8-cb19a80cffbe"
      },
      "source": [
        "output_ids=[]\n",
        "for i in token_label:\n",
        "  temp=[]\n",
        "  for j in i:\n",
        "    temp.append(tag2id[j])\n",
        "  output_ids.append(temp)\n",
        "output_ids = pad_sequences(output_ids, maxlen=max_len,dtype='long',padding='post', truncating='post')\n",
        "print(output_ids[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18  1  1  1 17 17  1  1  1  2  1  1  1  1  1  2  1  1  1  1  1  3  1  1\n",
            "  1  1  1 19  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ia72c0OgtafW",
        "colab_type": "text"
      },
      "source": [
        "Convert labels back to tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FjoRECEteAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make id to tag dictionary\n",
        "id2tag = {tag2id[key]:key for key in tag2id.keys()}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKUuTW9tyJ_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee335de0-2291-4695-c242-e0b780b2843f"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "n_gpu"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM3ucQ-Yy2og",
        "colab_type": "text"
      },
      "source": [
        "Split data into training and validation 80% for train 20% for validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLYQ7vl6yRNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs, val_inputs, tr_tags, val_tags,tr_masks, val_masks,tr_segs, val_segs = \\\n",
        "train_test_split(input_ids, output_ids, mask,segment_id, \\\n",
        "                 random_state=4, test_size=0.2)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhrVTB61zl_T",
        "colab_type": "text"
      },
      "source": [
        "Set data into tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPHacMEUzeVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)\n",
        "tr_segs = torch.tensor(tr_segs)\n",
        "val_segs = torch.tensor(val_segs)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCnVZKQx0-Ad",
        "colab_type": "text"
      },
      "source": [
        "# put data into data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnGiBDrf0L7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "# Drop last can make batch training better for the last one\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size,drop_last=True)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size, drop_last=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaCTwJsL1Xzy",
        "colab_type": "text"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh18yuG_1W3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForTokenClassification.from_pretrained('/content/drive/My Drive/data/bert_model', num_labels=20)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_bCWUGB2BCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPSua5ty2F_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 5\n",
        "max_grad_norm = 1.0\n",
        "num_train_optimization_steps = int( len(tr_inputs) / batch_size) * epochs\n",
        "num_train_optimization_steps = 10"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--t7yZIx3GPP",
        "colab_type": "text"
      },
      "source": [
        "Set pre-trained Bert model for word embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7ibU72I3F8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    # Fine tune model all layer parameters\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    # Only fine tune classifier parameters\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1pxjJsF2jn8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "3f0c83ff-955b-435d-ae52-5ba3fc3ed6cd"
      },
      "source": [
        "model.train()\n",
        "print(\"***** Running training *****\")\n",
        "print(\"  Num examples = %d\"%(len(tr_inputs)))\n",
        "print(\"  Batch size = %d\"%(batch_size))\n",
        "print(\"  Num steps = %d\"%(num_train_optimization_steps))\n",
        "for _ in trange(epochs, desc='Epoch'):\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(b_input_ids, token_type_ids = None, \\\n",
        "                    attention_mask = b_input_mask, labels=b_labels)\n",
        "    loss, scores = outputs[:2]\n",
        "\n",
        "    if n_gpu>1:\n",
        "      loss = loss.mean()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # track train loss\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += batch_size\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "    # gradient clipping\n",
        "    torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "    \n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "  # print train loss per epoch\n",
        "  print('Train loss: {}'.format(tr_loss/nb_tr_steps))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 365\n",
            "  Batch size = 10\n",
            "  Num steps = 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 1/5 [00:02<00:10,  2.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 1.208073819677035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 2/5 [00:05<00:07,  2.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.34124322090711856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 3/5 [00:07<00:05,  2.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.1312011725579699\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 4/5 [00:10<00:02,  2.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.06790051609277725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 5/5 [00:13<00:00,  2.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.03716581019883355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkJE_ST9IFYz",
        "colab_type": "text"
      },
      "source": [
        "Eval model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OajhXxAK9lz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab208054-6bb0-4100-f502-bf7cd6d88460"
      },
      "source": [
        "bert_out_address = '/content/saved model'\n",
        "model_to_save = model\n",
        "output_model_file = os.path.join(bert_out_address, \"pytorch_model.bin\")\n",
        "output_config_file = os.path.join(bert_out_address, \"config.json\")\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_vocabulary(bert_out_address)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/saved model/vocab.txt',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD-1aXFnLil7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForTokenClassification.from_pretrained(bert_out_address,num_labels=20)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQgIRdNLIEWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.cuda()\n",
        "model.eval()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oskV5qw3IJC4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "64efedd6-8517-49a1-971e-d092cad95f2b"
      },
      "source": [
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_step, nb_eval_example = 0, 0\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "print(\"***** Running evaluation *****\")\n",
        "print(\"  Num examples ={}\".format(len(val_inputs)))\n",
        "print(\"  Batch size = {}\".format(batch_size))\n",
        "\n",
        "for step, batch in enumerate(valid_dataloader):\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  input_ids, input_mask, label_ids = batch\n",
        "  with torch.no_grad():\n",
        "    outputs = model(input_ids, token_type_ids = None,\n",
        "                    attention_mask = input_mask,)\n",
        "    logits = outputs[0]\n",
        "    logits = torch.argmax(F.log_softmax(logits, dim=2), dim=2)\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = label_ids.to('cpu').numpy()\n",
        "    for i, mask in enumerate(input_mask):\n",
        "      temp_1 = []\n",
        "      temp_2 = []\n",
        "      for j, m in enumerate(mask):\n",
        "        # # print(label_ids[i,j])\n",
        "        if m:\n",
        "          if id2tag[label_ids[i][j]] != 'X' and id2tag[label_ids[i][j]] != '[SEP]':\n",
        "            if id2tag[label_ids[i][j]] != '[CLS]':\n",
        "              temp_1.append(id2tag[label_ids[i][j]])\n",
        "              temp_2.append(id2tag[logits[i][j]])\n",
        "          else:\n",
        "              break\n",
        "      y_true.append(temp_1)\n",
        "      y_pred.append(temp_2)\n",
        "\n",
        "print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
        "print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
        "report = classification_report(y_true, y_pred)\n",
        "print(report)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running evaluation *****\n",
            "  Num examples =92\n",
            "  Batch size = 10\n",
            "f1 socre: 0.909871\n",
            "Accuracy score: 0.986592\n",
            "           precision    recall  f1-score   support\n",
            "\n",
            "      per       0.93      0.88      0.90        16\n",
            "      org       0.74      0.82      0.78        17\n",
            "      geo       0.97      0.91      0.94        34\n",
            "      gpe       0.91      0.97      0.94        33\n",
            "      tim       1.00      1.00      1.00        15\n",
            "      art       0.00      0.00      0.00         1\n",
            "\n",
            "micro avg       0.91      0.91      0.91       116\n",
            "macro avg       0.91      0.91      0.91       116\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}